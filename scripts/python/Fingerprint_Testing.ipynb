{"cells":[{"cell_type":"markdown","metadata":{"id":"EAc34dCbp2Ra"},"source":["This file is a testing playground/sandbox for the usage of audio processing libraries in Python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6199,"status":"ok","timestamp":1644201930461,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"lD71ZCqKmk5U","outputId":"6fceee22-1873-4c6e-9664-7ed304cff364"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting essentia\n","  Downloading essentia-2.1b6.dev609-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n","\u001b[K     |████████████████████████████████| 13.7 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from essentia) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from essentia) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from essentia) (1.15.0)\n","Installing collected packages: essentia\n","Successfully installed essentia-2.1b6.dev609\n"]}],"source":["!pip install essentia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4912,"status":"ok","timestamp":1644201935357,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"spbl5z-KmvmS","outputId":"31df2b53-122b-40b1-f013-71be47bac4bd"},"outputs":[],"source":["!pip install pyacoustid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylHq4UeimSLb"},"outputs":[],"source":["import essentia\n","from essentia.standard import *\n","import acoustid as ai\n","import chromaprint as ch\n","from pylab import plot, show, figure, imshow\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4011,"status":"ok","timestamp":1644201944206,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"GQjZTXOvrDnE","outputId":"e3f96926-09a7-41d0-f87a-8a7657faf914"},"outputs":[],"source":["!pip install wavio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":425,"status":"error","timestamp":1643787772787,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"33zXJBtmmdJf","outputId":"665eb4d7-6563-488d-8e72-6d061f2414b4"},"outputs":[],"source":["# This takes in a string `filename` and outputs a list of numbers which indicates \n","# the audio fingerprint (can be used for graphing)\n","\n","def getFingerprint(filename):\n","  audio = es.MonoLoader(filename=filename, sampleRate=44100)()\n","  plot(audio)\n","  fingerprint = es.Chromaprinter()(audio)\n","  c = bytes(fingerprint, \"utf_8\")\n","  print(filename, c)\n","  fp, v = ch.decode_fingerprint(c)\n","  return fp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":424,"status":"error","timestamp":1643787715000,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"77bXPu2ZwPMx","outputId":"96fb3213-544f-4ea6-9ccf-2e1a07c5464e"},"outputs":[],"source":["#ChromeCrossSimilarity\n","import essentia.standard as estd\n","from essentia.pytools.spectral import hpcpgram\n","\n","daddyFilePath = './L1R1V1.mp3'\n","audio1 = es.MonoLoader(filename=daddyFilePath, sampleRate=32000)()\n","filePathAudio = ['./L1C1V1 (mp3cut.net).mp3', './L1C2V1 (mp3cut.net).mp3', \n","            './L1C1V1.mp3', './L1C1V2.mp3', './L1C2V1.mp3', './L1C3V1.mp3',\n","             './L1L1V1.mp3', './L1L2V1.mp3', './L1L3V1.mp3', './L1R1V1.mp3',\n","             './L1R2V1.mp3', './L1R3V1.mp3', './L2C1V1.mp3', './L2C2V1.mp3',\n","             './L3C1V1.mp3', './L3C2V1.mp3', './L3C3V1.mp3'\n","            ]\n","audio1_hpcp = hpcpgram(audio1, sampleRate=32000)\n","print(\"Comparing with daddy path = \" + daddyFilePath)\n","for i in range(len(filePathAudio)):\n","  audio2 = es.MonoLoader(filename = filePathAudio[i], sampleRate=32000)()\n","  audio2_hpcp = hpcpgram(audio2, sampleRate=32000)\n","\n","  crp = estd.ChromaCrossSimilarity(frameStackSize=2,\n","                                  frameStackStride=1,\n","                                  binarizePercentile=0.9,\n","                                  oti=True)\n","\n","  pair_crp = crp(audio1_hpcp, audio2_hpcp)\n","\n","  score_matrix, distance = estd.CoverSongSimilarity(disOnset=0.5,\n","                                                    disExtension=0.5,\n","                                                    alignmentType='serra09',\n","                                                    distanceType='asymmetric')(pair_crp)\n","  print('Similarity distance: %s' % distance + \"with \" + filePathAudio[i])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":679,"status":"error","timestamp":1643787718669,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"khjh6ON6-CYW","outputId":"dc7c1bf1-316b-4246-96fb-eb3ff2ec514e"},"outputs":[],"source":["from scipy.signal import chirp, spectrogram\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.io.wavfile import write\n","import IPython\n","import wavio\n","\n","\n","def plot_spectrogram(title, w, fs):\n","    ff, tt, Sxx = spectrogram(w, fs=fs, nperseg=256, nfft=576)\n","    plt.pcolormesh(tt, ff[:145], Sxx[:145], cmap='gray_r', shading='gouraud')\n","    plt.title(title)\n","    plt.xlabel('t (sec)')\n","    plt.ylabel('Frequency (Hz)')\n","    plt.grid()\n","\n","samplerate = 44100; fs = 12000\n","t = np.linspace(0., 100., 44100);\n","print(t)\n","f0 = 10000\n","f1 = 2200000\n","t1=10\n","y = chirp(t, f0, f1, 1, method='linear')\n","plot_spectrogram(\"t43\",y, fs)\n","amplitude = np.iinfo(np.int16).max\n","data = amplitude * np.sin(2. * np.pi * fs * t)\n","#  Test the recoded *.wav file\n","\n","wavio.write(\"sine.wav\", y, samplerate, sampwidth=3)\n","#write(\"chirp.wav\", samplerate, y.astype(np.int16))\n","IPython.display.Audio('./sine.wav')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"executionInfo":{"elapsed":326,"status":"error","timestamp":1641876187145,"user":{"displayName":"Anuj Bhatia","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01393314668717070604"},"user_tz":-480},"id":"PtfQGAY7csn0","outputId":"34b8c7b3-be1d-4c44-dc7b-ac424e95633e"},"outputs":[],"source":["# Loading audio file\n","audio = MonoLoader(filename='./hiphop.mp3')()\n","\n","# Phase 1: compute the onset detection function\n","# The OnsetDetection algorithm provides various onset detection functions. Let's use two of them.\n","\n","od1 = OnsetDetection(method='hfc')\n","od2 = OnsetDetection(method='complex')\n","\n","# Let's also get the other algorithms we will need, and a pool to store the results\n","w = Windowing(type = 'hann')\n","fft = FFT() # this gives us a complex FFT\n","c2p = CartesianToPolar() # and this turns it into a pair (magnitude, phase)\n","pool = essentia.Pool()\n","\n","# Computing onset detection functions.\n","for frame in FrameGenerator(audio, frameSize = 1024, hopSize = 512):\n","    mag, phase, = c2p(fft(w(frame)))\n","    pool.add('features.hfc', od1(mag, phase))\n","    pool.add('features.complex', od2(mag, phase))\n","\n","# Phase 2: compute the actual onsets locations\n","onsets = Onsets()\n","\n","onsets_hfc = onsets(# this algo expects a matrix, not a vector\n","                    essentia.array([ pool['features.hfc'] ]),\n","\n","                    # you need to specify weights, but as there is only a single\n","                    # function, it doesn't actually matter which weight you give it\n","                    [ 1 ])\n","\n","onsets_complex = onsets(essentia.array([ pool['features.complex'] ]), [ 1 ])\n","\n","\n","# Mark onsets on the audio, which we'll write back to disk\n","# We use beeps instead of white noise and stereo signal as it's more distinctive\n","\n","silence = [0.] * len(audio)\n","\n","beeps_hfc = AudioOnsetsMarker(onsets=onsets_hfc, type='beep')(silence)\n","AudioWriter(filename='audio/hiphop_onsets_hfc_stereo.mp3', format='mp3')(StereoMuxer()(audio, beeps_hfc))\n","\n","beeps_complex = AudioOnsetsMarker(onsets=onsets_complex, type='beep')(silence)\n","AudioWriter(filename='audio/hiphop_onsets_complex_stereo.mp3', format='mp3')(StereoMuxer()(audio, beeps_complex))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":731,"status":"ok","timestamp":1643787863614,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"W2j3P-tw8_cN","outputId":"e32f85e3-8acd-4484-ed40-56dcc4850eab"},"outputs":[],"source":["#Creating amplitude vs frequency graph\n","\n","import wave\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.io import wavfile\n","\n","wr = wave.open('16_C.wav', 'r')\n","sz = 44100 \n","da = np.fromstring(wr.readframes(sz), dtype=np.int16)\n","left, right = da[0::2], da[1::2]\n","\n","lf, rf = abs(np.fft.rfft(left)), abs(np.fft.rfft(right))\n","\n","plt.figure(1)\n","print(left)\n","x = np.arange(44100)/44100\n","plt.plot(x, left)\n","b = plt.subplot(212)\n","b.set_xscale('log')\n","b.set_xlabel('frequency [Hz]')\n","b.set_ylabel('|amplitude|')\n","plt.plot(lf)\n","#plt.savefig('sample-graph.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1568,"status":"ok","timestamp":1644202336693,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"iR-W1pjWCsyf","outputId":"f9c3f7ae-ad66-4beb-912c-473fc010e343"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.io import wavfile\n","from sklearn import preprocessing\n","from scipy.fftpack import fft\n","import matplotlib.pyplot as plt\n","\n","\n","\n","def ampVsFreq(filename):\n","  plt.title('Amplitude vs Frequency')\n","  sampFreq, sound = wavfile.read(filename)\n","  signal = sound[:,0]\n","\n","  fft_spectrum = np.fft.rfft(signal)\n","  freq = np.fft.rfftfreq(signal.size, d=1./sampFreq)\n","\n","  fft_spectrum_abs = np.abs(fft_spectrum)\n","\n","  plt.plot(freq, fft_spectrum_abs)\n","  plt.xlabel(\"frequency, Hz\")\n","  plt.ylabel(\"Amplitude, units\")\n","  plt.show()\n","\n","  plt.plot(sound)\n","  plt.show()\n","\n","\n","def ampVsSample(filename):\n","  sampFreq, sound = wavfile.read(filename)\n","  plt.title('Amplitude vs Sample index')\n","  plt.plot(sound)\n","  plt.xlabel('Sample')\n","  plt.ylabel('Amplitude')\n","  plt.show()\n","\n","#ampVsSample('16_C.wav')\n","ampVsFreq('16_C.wav')\n","ampVsFreq('test3.wav')\n","#ampVsFreq('output.wav')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":1514,"status":"ok","timestamp":1643788272632,"user":{"displayName":"Anubhav Garg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14049827857970065216"},"user_tz":-480},"id":"KqT3OdSYEpmH","outputId":"7726d921-057f-48c7-f7a8-eefb16d6a2c5"},"outputs":[],"source":["#High-pass filter means removing frequency higher than a certain cutoff frequency\n","import matplotlib.pyplot as plot\n","import numpy\n","from scipy.io import wavfile\n","from scipy import signal\n","from scipy.signal import filtfilt\n","import wave\n","\n","\n","def specto(filename):\n","  samplingFrequency, signalData = wavfile.read(filename)\n","\n","  audLeft = signalData[:,0] #selects only left\n","\n","  plot.subplot(212)\n","  #plot.title('Left Spectogram')\n","\n","  powerSpectrumL, frequenciesFoundL, timeL, imageAxisL = plot.specgram(audLeft, Fs=samplingFrequency) \n","  plot.xlabel('Time')\n","  plot.ylabel('Left Frequency')\n","\n","  plot.show()\n","\n","def HighPassFilter(filename):\n","  samplingFrequency, signalData = wavfile.read(filename)\n","  \n","  nyquist = samplingFrequency // 2\n","  norm_cutoff = 10000 / nyquist\n","  \n","  b = signal.firwin(255, norm_cutoff, pass_zero=False)\n","  #newSignalData = signal.lfilter(b, [1.0], signalData)\n","  newSignalData = filtfilt(b, 1, signalData, axis=0)\n","  wavfile.write('test3.wav', samplingFrequency, newSignalData.astype(np.int16))\n","  \n","  specto('test3.wav');\n","\n","def fft_ours(filename):\n","  sampFreq, sound = wavfile.read(filename)\n","  signal = sound[:,0]\n","\n","  fft_spectrum = np.fft.rfft(signal)\n","  freq = np.fft.rfftfreq(signal.size, d=1./sampFreq)\n","  \n","ff = 'test.wav'\n","specto('16_C.wav')\n","specto(ff)\n","HighPassFilter(ff)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Fyp.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
